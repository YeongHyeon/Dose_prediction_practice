{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c942536",
   "metadata": {},
   "source": [
    "# Point-A Reference Plan Optimization (v0.3)\n",
    "\n",
    "This notebook revisits the previous `point_a_plan` workflow and adds a cvxpy-based dwell-time optimizer.\n",
    "Tandem reference points stay pinned at 100% of the prescription, ovoid surface points are capped at 140%, and ovoid 5 mm depth points must respect an EBRT+BT cumulative EQD2 <= 85 Gy (alpha/beta = 3).\n",
    "The steps below load the brachy plan, assemble TG-43 influence matrices at the reference points, and solve a convex program that minimally perturbs the plan dwell times while satisfying those dose/EQD2 requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp\n",
    "import copy\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Any, Dict, Iterable, List, Tuple, Sequence\n",
    "\n",
    "from dataclasses import dataclass, replace\n",
    "from itertools import product\n",
    "\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except ImportError:  # pragma: no cover - fallback when running as a script\n",
    "    def display(obj):\n",
    "        print(obj)\n",
    "\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "import tg43.dicom_helper as dhelp\n",
    "import tg43.contour_helper as chelp\n",
    "import tg43.dose_calculation as dosecal\n",
    "import tg43.utils as utils\n",
    "import tg43.visualization as vis\n",
    "\n",
    "import tg43.rtstruct_export as rtexport\n",
    "import src.dataloader as dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ea9187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hyperparams(config_path: Path) -> DictConfig:\n",
    "    \"\"\"Load run-time hyperparameters from YAML.\"\"\"\n",
    "    cfg = OmegaConf.load(config_path)\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def resolve_single(path_iterable: Iterable[Path], description: str) -> Path:\n",
    "    \"\"\"Return the first existing path from ``path_iterable``.\"\"\"\n",
    "    candidates = sorted(path_iterable)\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"No files found for {description}.\")\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def load_case_paths(root: Path, case_id: Path) -> Dict[str, Path]:\n",
    "    \"\"\"Collect CT/RTDICOM paths for a given case identifier.\"\"\"\n",
    "    case_dir = root / f\"{case_id}\"\n",
    "    if not case_dir.exists():\n",
    "        raise FileNotFoundError(f\"Case directory not found: {case_dir}\")\n",
    "\n",
    "    return {\n",
    "        \"ct\": resolve_single(case_dir.glob(\"CT*/*\"), \"CT series\"),\n",
    "        \"dose\": resolve_single(case_dir.glob(\"RTDOSE*/*/*.dcm\"), \"RTDOSE file\"),\n",
    "        \"plan\": resolve_single(case_dir.glob(\"RTPLAN*/*/*.dcm\"), \"RTPLAN file\"),\n",
    "        \"struct\": resolve_single(case_dir.glob(\"RTSTRUCT*/*/*.dcm\"), \"RTSTRUCT file\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649ac9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reference_point(dose_ref_points: Dict[str, Any], label: str) -> Dict[str, Any]:\n",
    "    for entry in dose_ref_points:\n",
    "        if entry[\"description\"].strip().lower() == label.lower():\n",
    "            return entry\n",
    "    raise ValueError(f\"{label} reference point not found in RTPLAN.\")\n",
    "\n",
    "\n",
    "def filter_redundant_positions(positions: Iterable[np.ndarray]) -> np.ndarray:\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for pos in positions:\n",
    "        if pos is None:\n",
    "            continue\n",
    "        arr = np.asarray(pos, dtype=float)\n",
    "        key = tuple(arr.tolist())\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        unique.append(arr)\n",
    "    if not unique:\n",
    "        return np.zeros((0, 3), dtype=float)\n",
    "    return np.vstack(unique)\n",
    "\n",
    "\n",
    "def compute_reference_point_clouds(\n",
    "    rt_channels,\n",
    "    aux_points: Dict[str, Any],\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Return left/right ovoid and tandem reference point sets in centimetres.\"\"\"\n",
    "    if len(rt_channels) < 3:\n",
    "        raise ValueError(\"Expected at least 3 channels (left/right ovoid + tandem).\")\n",
    "\n",
    "    pos_ovoid_left = filter_redundant_positions(rt_channels[0].positions_cm)\n",
    "    pos_ovoid_right = filter_redundant_positions(rt_channels[1].positions_cm)\n",
    "    pos_tandem = filter_redundant_positions(rt_channels[2].positions_cm)\n",
    "\n",
    "    if not pos_ovoid_left.size or not pos_ovoid_right.size or not pos_tandem.size:\n",
    "        raise ValueError(\"Missing dwell positions for ovoid/tandem channels.\")\n",
    "\n",
    "    if '13' in aux_points[\"rtplan_description\"]:\n",
    "        offset_to_ovoid_surface = 0.75\n",
    "        offset_over_ovoid_surface = 0.5\n",
    "        offset_tandem = 2.0\n",
    "    else: # other cases\n",
    "        offset_to_ovoid_surface = 0.8\n",
    "        offset_over_ovoid_surface = 0.5\n",
    "        offset_tandem = 2.0\n",
    "\n",
    "    alt_point = get_reference_point(aux_points[\"dose_reference_points\"], \"Alt\")\n",
    "    art_point = get_reference_point(aux_points[\"dose_reference_points\"], \"Art\")\n",
    "    pos_a_left = np.asarray(alt_point[\"positions_cm\"], dtype=float)\n",
    "    pos_a_right = np.asarray(art_point[\"positions_cm\"], dtype=float)\n",
    "\n",
    "    def _unit_vector(vec: np.ndarray) -> np.ndarray:\n",
    "        norm = np.linalg.norm(vec)\n",
    "        if norm <= 0.0:\n",
    "            raise ValueError(\"Encountered zero-length vector while normalising reference axes.\")\n",
    "        return vec / norm\n",
    "\n",
    "    ovoid_center = (np.mean(pos_ovoid_right, axis=0) + np.mean(pos_ovoid_left, axis=0)) / 2\n",
    "    ovoid_axis = np.mean(pos_ovoid_right, axis=0) - np.mean(pos_ovoid_left, axis=0)\n",
    "    tandem_axis = pos_tandem[-1] - pos_tandem[0]\n",
    "\n",
    "    ovoid_dir = _unit_vector(ovoid_axis)\n",
    "    tandem_dir = _unit_vector(tandem_axis)\n",
    "    dot_val = float(np.clip(np.dot(ovoid_dir, tandem_dir), -1.0, 1.0))\n",
    "    angle_deg = np.degrees(np.arccos(dot_val))\n",
    "    print(f\"Angle between ovoid and tandem axes: {angle_deg:.2f} deg\")\n",
    "\n",
    "    ref_ovoid_surface_left = pos_ovoid_left - (ovoid_dir * offset_to_ovoid_surface)\n",
    "    ref_ovoid_surface_right = pos_ovoid_right + (ovoid_dir * offset_to_ovoid_surface)\n",
    "    ref_ovoid_left = pos_ovoid_left - (ovoid_dir * (offset_to_ovoid_surface + offset_over_ovoid_surface))\n",
    "    ref_ovoid_right = pos_ovoid_right + (ovoid_dir * (offset_to_ovoid_surface + offset_over_ovoid_surface))\n",
    "\n",
    "    ref_tandem_left = pos_tandem - (ovoid_dir * offset_tandem)\n",
    "    ref_tandem_right = pos_tandem + (ovoid_dir * offset_tandem)\n",
    "\n",
    "    threshold_distance = 0.5\n",
    "    mask = np.linalg.norm(pos_tandem - ovoid_center, axis=1) >= threshold_distance\n",
    "    ref_tandem_left = ref_tandem_left[mask]\n",
    "    ref_tandem_right = ref_tandem_right[mask]\n",
    "\n",
    "    def _filter_by_point_a(ref_pts: np.ndarray, point_a: np.ndarray) -> np.ndarray:\n",
    "        if ref_pts.shape[0] < 2:\n",
    "            return ref_pts\n",
    "        delta_cm = ref_pts - point_a\n",
    "        axis = ref_pts[-1] - ref_pts[0]\n",
    "        axis_norm = np.linalg.norm(axis)\n",
    "        if axis_norm <= 0.0:\n",
    "            return ref_pts\n",
    "        axis = axis / axis_norm\n",
    "        proj_mm = (delta_cm @ axis) * 10.0\n",
    "        keep = proj_mm <= 5.0\n",
    "        return ref_pts[keep]\n",
    "\n",
    "    ref_tandem_left = _filter_by_point_a(ref_tandem_left[1:], pos_a_left)\n",
    "    ref_tandem_right = _filter_by_point_a(ref_tandem_right[1:], pos_a_right)\n",
    "\n",
    "    def _slice_points(points: np.ndarray) -> np.ndarray:\n",
    "        if points.shape[0] >= 3:\n",
    "            return points[1:3]\n",
    "        if points.shape[0] <= 1:\n",
    "            return points\n",
    "        return points[1:]\n",
    "\n",
    "    ovoid_surface_left = _slice_points(ref_ovoid_surface_left)\n",
    "    ovoid_surface_right = _slice_points(ref_ovoid_surface_right)\n",
    "    ovoid_5mm_left = _slice_points(ref_ovoid_left)\n",
    "    ovoid_5mm_right = _slice_points(ref_ovoid_right)\n",
    "\n",
    "    return {\n",
    "        \"ovoid_surface_left\": ovoid_surface_left,\n",
    "        \"ovoid_surface_right\": ovoid_surface_right,\n",
    "        \"ovoid_5mm_left\": ovoid_5mm_left,\n",
    "        \"ovoid_5mm_right\": ovoid_5mm_right,\n",
    "        \"ref_tandem_left\": ref_tandem_left,\n",
    "        \"ref_tandem_right\": ref_tandem_right,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_influence_matrix(\n",
    "    dwells: List[dosecal.DwellPoint],\n",
    "    ref_points_cm: np.ndarray,\n",
    "    tables: dosecal.TG43TableSet,\n",
    ") -> np.ndarray:\n",
    "    pts = np.asarray(ref_points_cm, dtype=float)\n",
    "    if pts.size == 0:\n",
    "        return np.zeros((0, len(dwells)))\n",
    "    influence = np.zeros((pts.shape[0], len(dwells)))\n",
    "    for idx, dwell in enumerate(dwells):\n",
    "        influence[:, idx] = (\n",
    "            dosecal.compute_tg43_dose_at_points(\n",
    "                [dwell], pts, tables, dwell_time_override_s=1.0\n",
    "            )  # convert Gy per second to cGy per second\n",
    "        )\n",
    "    return influence\n",
    "\n",
    "\n",
    "def build_reference_constraints(\n",
    "    ref_sets: Dict[str, np.ndarray],\n",
    "    dwells: List[dosecal.DwellPoint],\n",
    "    tables: dosecal.TG43TableSet,\n",
    "    prescription_dose_cgy: float,\n",
    ") -> Tuple[Dict[str, Dict[str, Any]], List[Dict[str, Any]]]:\n",
    "    def _group_from_label(label: str) -> str:\n",
    "        name = label.lower()\n",
    "        if \"tandem\" in name:\n",
    "            return \"tandem\"\n",
    "        if \"surface\" in name:\n",
    "            return \"ovoid_surface\"\n",
    "        if \"5mm\" in name:\n",
    "            return \"ovoid_5mm\"\n",
    "        raise ValueError(f\"Unable to classify reference label '{label}'.\")\n",
    "\n",
    "    specs = {\n",
    "        \"tandem\": {\"target_scale\": 1.0, \"sense\": \"lower_bound\"},\n",
    "        \"ovoid_surface\": {\"target_scale\": 1.4, \"sense\": \"upper_bound\"},\n",
    "        \"ovoid_5mm\": {\"sense\": \"eqd2_upper\"},\n",
    "    }\n",
    "    grouped: Dict[str, Dict[str, Any]] = defaultdict(\n",
    "        lambda: {\"matrix_rows\": [], \"targets\": [], \"rows\": []}\n",
    "    )\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for label, points in ref_sets.items():\n",
    "        pts = np.asarray(points, dtype=float)\n",
    "        if pts.size == 0:\n",
    "            continue\n",
    "        group = _group_from_label(label)\n",
    "        influence = compute_influence_matrix(dwells, pts, tables)\n",
    "        entry = grouped[group]\n",
    "        entry[\"matrix_rows\"].append(influence)\n",
    "        target_val = None\n",
    "        target_scale = specs[group].get(\"target_scale\")\n",
    "        if target_scale is not None:\n",
    "            target_val = prescription_dose_cgy * target_scale\n",
    "            entry[\"targets\"].append(np.full(pts.shape[0], target_val))\n",
    "        for idx in range(pts.shape[0]):\n",
    "            record = {\n",
    "                \"group\": group,\n",
    "                \"subset\": label,\n",
    "                \"point_index\": idx,\n",
    "                \"point_cm\": pts[idx].tolist(),\n",
    "                \"constraint_kind\": specs[group][\"sense\"],\n",
    "                \"target_dose_cgy\": target_val if target_val is not None else float(\"nan\"),\n",
    "            }\n",
    "            entry[\"rows\"].append(record)\n",
    "            rows.append(record)\n",
    "\n",
    "    constraint_groups: Dict[str, Dict[str, Any]] = {}\n",
    "    for group, entry in grouped.items():\n",
    "        matrix = (\n",
    "            np.vstack(entry[\"matrix_rows\"]) if entry[\"matrix_rows\"] else np.zeros((0, len(dwells)))\n",
    "        )\n",
    "        targets = (\n",
    "            np.concatenate(entry[\"targets\"]) if entry[\"targets\"] else None\n",
    "        )\n",
    "        constraint_groups[group] = {\n",
    "            \"matrix\": matrix,\n",
    "            \"target\": targets,\n",
    "            \"rows\": entry[\"rows\"],\n",
    "        }\n",
    "    return constraint_groups, rows\n",
    "@dataclass\n",
    "class ApplicatorFrame:\n",
    "    rotation: np.ndarray\n",
    "    translation_mm: np.ndarray\n",
    "    anchor_mm: np.ndarray\n",
    "    description: str = \"ECS\"\n",
    "\n",
    "    @property\n",
    "    def inverse_rotation(self) -> np.ndarray:\n",
    "        return self.rotation.T\n",
    "\n",
    "    def transform_points_mm(self, pts_mm):\n",
    "        arr = np.asarray(pts_mm, dtype=float)\n",
    "        if arr.size == 0:\n",
    "            return arr.copy()\n",
    "        orig_shape = arr.shape\n",
    "        arr = arr.reshape(-1, 3)\n",
    "        transformed = (self.rotation @ arr.T).T + self.translation_mm\n",
    "        return transformed.reshape(orig_shape)\n",
    "\n",
    "    def inverse_transform_points_mm(self, pts_mm):\n",
    "        arr = np.asarray(pts_mm, dtype=float)\n",
    "        if arr.size == 0:\n",
    "            return arr.copy()\n",
    "        orig_shape = arr.shape\n",
    "        arr = arr.reshape(-1, 3)\n",
    "        restored = (self.inverse_rotation @ (arr - self.translation_mm).T).T\n",
    "        return restored.reshape(orig_shape)\n",
    "\n",
    "    def transform_points_cm(self, pts_cm):\n",
    "        arr = np.asarray(pts_cm, dtype=float)\n",
    "        if arr.size == 0:\n",
    "            return arr.copy()\n",
    "        return self.transform_points_mm(arr * 10.0) / 10.0\n",
    "\n",
    "    def inverse_transform_points_cm(self, pts_cm):\n",
    "        arr = np.asarray(pts_cm, dtype=float)\n",
    "        if arr.size == 0:\n",
    "            return arr.copy()\n",
    "        restored = self.inverse_transform_points_mm(arr * 10.0)\n",
    "        return restored / 10.0\n",
    "\n",
    "def build_ecs_coordinate_frame(\n",
    "    rt_channels,\n",
    "    aux_points,\n",
    "    *,\n",
    "    plane_offset_mm: float = 20.0,\n",
    ") -> ApplicatorFrame:\n",
    "    if len(rt_channels) < 3:\n",
    "        raise ValueError(\"Need at least 3 channels (two ovoids + tandem) to define ECS frame.\")\n",
    "\n",
    "    def _nonnull_positions(channel):\n",
    "        coords = [np.asarray(p, dtype=float) for p in channel.positions_cm if p is not None]\n",
    "        if not coords:\n",
    "            raise ValueError(\"Channel is missing dwell positions.\")\n",
    "        arr = np.vstack(coords)\n",
    "        if arr.shape[1] != 3:\n",
    "            raise ValueError(\"Expected 3-D dwell positions.\")\n",
    "        return arr\n",
    "\n",
    "    def _unit(vec, label):\n",
    "        norm = np.linalg.norm(vec)\n",
    "        if norm <= 0.0:\n",
    "            raise ValueError(f\"Encountered zero-length vector while building {label} axis.\")\n",
    "        return vec / norm\n",
    "\n",
    "    ovoid_left_cm = _nonnull_positions(rt_channels[0])\n",
    "    ovoid_right_cm = _nonnull_positions(rt_channels[1])\n",
    "    tandem_positions_cm = _nonnull_positions(rt_channels[2])\n",
    "    if tandem_positions_cm.shape[0] < 2:\n",
    "        raise ValueError(\"Tandem channel must have at least two dwell positions.\")\n",
    "    ovoid_left_centroid_mm = np.mean(ovoid_left_cm, axis=0) * 10.0\n",
    "    ovoid_right_centroid_mm = np.mean(ovoid_right_cm, axis=0) * 10.0\n",
    "    tandem_positions_mm = tandem_positions_cm * 10.0\n",
    "\n",
    "    art_point = get_reference_point(aux_points[\"dose_reference_points\"], \"Art\")\n",
    "    alt_point = get_reference_point(aux_points[\"dose_reference_points\"], \"Alt\")\n",
    "    art_mm = np.asarray(art_point[\"positions_cm\"], dtype=float) * 10.0\n",
    "    alt_mm = np.asarray(alt_point[\"positions_cm\"], dtype=float) * 10.0\n",
    "    point_a_axis = alt_mm - art_mm\n",
    "\n",
    "    z_axis = _unit(tandem_positions_mm[0] - tandem_positions_mm[-1], \"z\")\n",
    "\n",
    "    ovoid_axis_mm = ovoid_right_centroid_mm - ovoid_left_centroid_mm\n",
    "    lateral_component = ovoid_axis_mm - np.dot(ovoid_axis_mm, z_axis) * z_axis\n",
    "    if np.linalg.norm(lateral_component) <= 1e-6:\n",
    "        x_axis = _unit(point_a_axis, \"x (Point A)\")\n",
    "    else:\n",
    "        x_axis = _unit(lateral_component, \"x (ovoid span)\")\n",
    "    if np.dot(x_axis, point_a_axis) < 0:\n",
    "        x_axis = -x_axis\n",
    "\n",
    "    y_axis = _unit(np.cross(z_axis, x_axis), \"y\")\n",
    "    x_axis = _unit(np.cross(y_axis, z_axis), \"x\")\n",
    "\n",
    "    rotation = np.vstack([x_axis, y_axis, z_axis])\n",
    "\n",
    "    plane_normal = z_axis\n",
    "    plane_d = float(np.dot(plane_normal, art_mm))\n",
    "    line_vec = tandem_positions_mm[-1] - tandem_positions_mm[0]\n",
    "    denom = float(np.dot(plane_normal, line_vec))\n",
    "    if abs(denom) <= 1e-6:\n",
    "        t_plane = 0.0\n",
    "    else:\n",
    "        t_plane = (plane_d - float(np.dot(plane_normal, tandem_positions_mm[0]))) / denom\n",
    "    intersection_mm = tandem_positions_mm[0] + t_plane * line_vec\n",
    "\n",
    "    target_mm = np.array([0.0, 0.0, float(plane_offset_mm)], dtype=float)\n",
    "    translation_mm = target_mm - rotation @ intersection_mm\n",
    "\n",
    "    return ApplicatorFrame(\n",
    "        rotation=rotation,\n",
    "        translation_mm=translation_mm,\n",
    "        anchor_mm=intersection_mm,\n",
    "        description=\"ECS\",\n",
    "    )\n",
    "def transform_channels_to_frame(channels, frame: ApplicatorFrame):\n",
    "    transformed = []\n",
    "    for channel in channels:\n",
    "        new_positions = []\n",
    "        for pos in channel.positions_cm:\n",
    "            if pos is None:\n",
    "                new_positions.append(None)\n",
    "            else:\n",
    "                new_positions.append(frame.transform_points_cm(pos))\n",
    "        transformed.append(replace(channel, positions_cm=new_positions))\n",
    "    return transformed\n",
    "\n",
    "def transform_point_sets(point_sets, frame: ApplicatorFrame):\n",
    "    transformed = {}\n",
    "    for label, pts in point_sets.items():\n",
    "        arr = np.asarray(pts, dtype=float)\n",
    "        if arr.size == 0:\n",
    "            transformed[label] = arr.copy()\n",
    "            continue\n",
    "        transformed[label] = frame.transform_points_cm(arr)\n",
    "    return transformed\n",
    "\n",
    "def resample_image_to_frame(\n",
    "    image,\n",
    "    frame: ApplicatorFrame,\n",
    "    *,\n",
    "    spacing_mm=1.0,\n",
    "    margin_mm: float = 5.0,\n",
    "    default_value: float = -1024.0,\n",
    "):\n",
    "    if np.isscalar(spacing_mm):\n",
    "        spacing_vals = np.array([float(spacing_mm)] * 3, dtype=float)\n",
    "    else:\n",
    "        spacing_vals = np.array(list(spacing_mm), dtype=float)\n",
    "    if spacing_vals.size != 3:\n",
    "        raise ValueError(\"spacing_mm must provide 3 values.\")\n",
    "    if np.any(spacing_vals <= 0):\n",
    "        raise ValueError(\"Output spacing must be positive.\")\n",
    "\n",
    "    size = np.array(image.GetSize(), dtype=float)\n",
    "    spacing = np.array(image.GetSpacing(), dtype=float)\n",
    "    direction = np.array(image.GetDirection(), dtype=float).reshape(3, 3)\n",
    "    origin = np.array(image.GetOrigin(), dtype=float)\n",
    "\n",
    "    corners = []\n",
    "    for idx in product([0, max(size[0] - 1, 0)], [0, max(size[1] - 1, 0)], [0, max(size[2] - 1, 0)]):\n",
    "        idx_vec = np.array(idx, dtype=float)\n",
    "        coord = origin + direction @ (spacing * idx_vec)\n",
    "        corners.append(coord)\n",
    "    corners = np.array(corners)\n",
    "    if not corners.size:\n",
    "        corners = origin[None, :]\n",
    "\n",
    "    corners_ecs = frame.transform_points_mm(corners)\n",
    "    mins = corners_ecs.min(axis=0) - margin_mm\n",
    "    maxs = corners_ecs.max(axis=0) + margin_mm\n",
    "    extent = np.maximum(maxs - mins, spacing_vals)\n",
    "    out_size = np.maximum(np.ceil(extent / spacing_vals).astype(int), 1)\n",
    "\n",
    "    inv_rotation = frame.inverse_rotation\n",
    "    inv_translation = -inv_rotation @ frame.translation_mm\n",
    "    transform = sitk.AffineTransform(3)\n",
    "    transform.SetMatrix(tuple(inv_rotation.reshape(-1)))\n",
    "    transform.SetTranslation(tuple(inv_translation.tolist()))\n",
    "\n",
    "    direction_out = (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0)\n",
    "    resampled_image = sitk.Resample(\n",
    "        image,\n",
    "        tuple(int(v) for v in out_size.tolist()),\n",
    "        transform,\n",
    "        sitk.sitkLinear,\n",
    "        tuple(mins.tolist()),\n",
    "        tuple(spacing_vals.tolist()),\n",
    "        direction_out,\n",
    "        float(default_value),\n",
    "        image.GetPixelIDValue(),\n",
    "    )\n",
    "    resampled_array = sitk.GetArrayFromImage(resampled_image)\n",
    "    metadata = {\n",
    "        \"spacing\": resampled_image.GetSpacing(),\n",
    "        \"origin\": resampled_image.GetOrigin(),\n",
    "        \"direction\": resampled_image.GetDirection(),\n",
    "        \"size\": resampled_image.GetSize(),\n",
    "    }\n",
    "    return resampled_image, resampled_array, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b77521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_hyperparams(Path(\"config.yaml\"))\n",
    "print(cfg)\n",
    "\n",
    "data_root = Path(cfg[\"run\"][\"data-root\"])\n",
    "case_id = Path(cfg[\"run\"][\"case\"])\n",
    "paths = load_case_paths(data_root, case_id)\n",
    "print(paths)\n",
    "\n",
    "rt_channels, aux_points = dhelp.load_rtplan_by_channel(paths[\"plan\"], all_points=True)\n",
    "prescription_dose_cgy = 600  # cGy per fraction\n",
    "n_ebrt = 25  # EBRT fractions\n",
    "d_ebrt_gy = 1.8  # Gy per EBRT fraction\n",
    "n_bt = 5  # number of brachytherapy fractions\n",
    "alpha_beta_gy = 3.0\n",
    "eqd2_limit_total_gy = 85.0\n",
    "prescription_dose_gy = prescription_dose_cgy / 100.0\n",
    "eqd2_ebrt_gy = n_ebrt * d_ebrt_gy * (d_ebrt_gy + alpha_beta_gy) / (2.0 + alpha_beta_gy)\n",
    "bt_eqd2_scale = n_bt / (2.0 + alpha_beta_gy)\n",
    "eqd2_allowable_bt_gy = eqd2_limit_total_gy - eqd2_ebrt_gy\n",
    "if eqd2_allowable_bt_gy <= 0:\n",
    "    raise ValueError(\"EBRT EQD2 exceeds total allowable EQD2.\")\n",
    "print(f\"Loaded {len(rt_channels)} channels; prescription dose = {prescription_dose_cgy} cGy ({prescription_dose_gy:.2f} Gy)\")\n",
    "print(f\"EQD2 budget: EBRT = {eqd2_ebrt_gy:.2f} Gy, BT allowance = {eqd2_allowable_bt_gy:.2f} Gy (limit {eqd2_limit_total_gy:.1f} Gy)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c21aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_sets = compute_reference_point_clouds(rt_channels, aux_points)\n",
    "for name, pts in reference_sets.items():\n",
    "    print(f\"{name}: {pts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966da9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_image, ct_array, ct_metadata = dhelp.load_ct_volume(paths[\"ct\"])\n",
    "applicator_frame = build_ecs_coordinate_frame(rt_channels, aux_points, plane_offset_mm=20.0)\n",
    "rt_channels_ecs = transform_channels_to_frame(rt_channels, applicator_frame)\n",
    "reference_sets_ecs = transform_point_sets(reference_sets, applicator_frame)\n",
    "\n",
    "reference_points_native = {\n",
    "    entry[\"description\"]: np.asarray(entry[\"positions_cm\"], dtype=float)\n",
    "    for entry in aux_points[\"dose_reference_points\"]\n",
    "    if entry.get(\"positions_cm\") is not None\n",
    "}\n",
    "reference_points_ecs = {\n",
    "    label: applicator_frame.transform_points_cm(pos)\n",
    "    for label, pos in reference_points_native.items()\n",
    "}\n",
    "\n",
    "default_hu = float(np.min(ct_array)) if ct_array is not None else -1024.0\n",
    "ct_ecs_image, ct_ecs_array, ct_ecs_metadata = resample_image_to_frame(\n",
    "    ct_image,\n",
    "    applicator_frame,\n",
    "    spacing_mm=1.0,\n",
    "    margin_mm=5.0,\n",
    "    default_value=default_hu,\n",
    ")\n",
    "\n",
    "print(\"Applicator rotation matrix (rows = X/Y/Z axes):\")\n",
    "print(applicator_frame.rotation)\n",
    "print(\"Native CT size/spacing:\", ct_image.GetSize(), ct_image.GetSpacing())\n",
    "print(\"ECS CT size/spacing:\", ct_ecs_image.GetSize(), ct_ecs_image.GetSpacing())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b29a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = {\n",
    "    'ovoid_surface_left': ('o', '#1f77b4'),\n",
    "    'ovoid_surface_right': ('o', '#d62728'),\n",
    "    'ovoid_5mm_left': ('x', '#1f77b4'),\n",
    "    'ovoid_5mm_right': ('x', '#d62728'),\n",
    "    'ref_tandem_left': ('^', '#2ca02c'),\n",
    "    'ref_tandem_right': ('^', '#9467bd'),\n",
    "}\n",
    "\n",
    "\n",
    "def plot_geometry(ax, channels, ref_sets, ref_points, title):\n",
    "    for channel in channels:\n",
    "        pts = [p for p in channel.positions_cm if p is not None]\n",
    "        if not pts:\n",
    "            continue\n",
    "        arr = np.asarray(pts, dtype=float)\n",
    "        ax.plot(arr[:, 0], arr[:, 1], arr[:, 2], marker='o', linewidth=1.0, label=f\"Channel {channel.channel_number}\")\n",
    "\n",
    "    for label, pts in ref_sets.items():\n",
    "        arr = np.asarray(pts, dtype=float)\n",
    "        if arr.size == 0:\n",
    "            continue\n",
    "        marker, color = markers.get(label, ('x', 'black'))\n",
    "        ax.scatter(arr[:, 0], arr[:, 1], arr[:, 2], s=35, marker=marker, color=color, label=label)\n",
    "\n",
    "    if ref_points:\n",
    "        for name, point in ref_points.items():\n",
    "            arr = np.asarray(point, dtype=float)\n",
    "            ax.scatter(arr[0], arr[1], arr[2], marker='s', s=45, color='black', label=f\"{name} (Point A)\")\n",
    "            ax.text(arr[0], arr[1], arr[2], f\" {name}\", fontsize=8)\n",
    "\n",
    "    ax.set_xlabel('X (cm)')\n",
    "    ax.set_ylabel('Y (cm)')\n",
    "    ax.set_zlabel('Z (cm)')\n",
    "    ax.set_title(title)\n",
    "    ax.view_init(elev=0, azim=-75, roll=0)\n",
    "    try:\n",
    "        ax.set_box_aspect([1, 1, 1])\n",
    "    except AttributeError:\n",
    "        pass\n",
    "    ax.legend(bbox_to_anchor=(1.05, 0.5), loc='center left')\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(14, 6))\n",
    "ax_native = fig.add_subplot(121, projection='3d')\n",
    "plot_geometry(ax_native, rt_channels, reference_sets, reference_points_native, 'Native (DICOM) geometry')\n",
    "ax_ecs = fig.add_subplot(122, projection='3d')\n",
    "plot_geometry(ax_ecs, rt_channels_ecs, reference_sets_ecs, reference_points_ecs, 'ECS-aligned geometry')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea54923",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = dosecal.load_nucletron_tg43_tables(\n",
    "    cfg[\"hyperparams\"][\"anisotropy_table\"],\n",
    "    cfg[\"hyperparams\"][\"radial_table\"],\n",
    ")\n",
    "dwells, _ = dosecal.dwells_from_records(rt_channels)\n",
    "channel_map = dataloader.map_channel_dwell_indices(rt_channels, dwells)\n",
    "required_channels = (\"ovoid_left\", \"ovoid_right\", \"tandem\")\n",
    "if len(channel_map) < len(required_channels):\n",
    "    raise ValueError(\"Not enough channels found for T&O optimisation.\")\n",
    "\n",
    "dwell_indices: List[int] = []\n",
    "dwell_records: List[Dict[str, Any]] = []\n",
    "for channel_idx, label in enumerate(required_channels):\n",
    "    indices = channel_map[channel_idx]\n",
    "    channel = rt_channels[channel_idx]\n",
    "    for local_idx, dwell_idx in enumerate(indices):\n",
    "        dwell_indices.append(dwell_idx)\n",
    "        dwell_records.append({\n",
    "            \"channel_label\": label,\n",
    "            \"channel_number\": channel.channel_number,\n",
    "            \"local_index\": local_idx,\n",
    "        })\n",
    "\n",
    "opt_dwells = [dwells[i] for i in dwell_indices]\n",
    "baseline_times = np.array([d.dwell_time_s for d in opt_dwells], dtype=float)\n",
    "constraint_groups, _ = build_reference_constraints(\n",
    "    reference_sets, opt_dwells, tables, prescription_dose_cgy\n",
    ")\n",
    "total_constraint_rows = int(sum(group_data[\"matrix\"].shape[0] for group_data in constraint_groups.values()))\n",
    "print(f\"Optimising {len(opt_dwells)} dwell positions with {total_constraint_rows} reference rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90903d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = cp.Variable(baseline_times.shape[0])\n",
    "updated_times = baseline_times + delta\n",
    "constraints = [updated_times >= 0]\n",
    "\n",
    "def _group_data(name: str) -> Dict[str, Any]:\n",
    "    return constraint_groups.get(\n",
    "        name,\n",
    "        {\n",
    "            \"matrix\": np.zeros((0, baseline_times.shape[0])),\n",
    "            \"target\": None,\n",
    "            \"rows\": [],\n",
    "        },\n",
    "    )\n",
    "\n",
    "tandem_group = _group_data(\"tandem\")\n",
    "ovoid_surface_group = _group_data(\"ovoid_surface\")\n",
    "ovoid_5mm_group = _group_data(\"ovoid_5mm\")\n",
    "\n",
    "if tandem_group[\"matrix\"].size and tandem_group[\"target\"] is not None:\n",
    "    constraints.append(tandem_group[\"matrix\"] @ updated_times >= tandem_group[\"target\"])\n",
    "if ovoid_surface_group[\"matrix\"].size and ovoid_surface_group[\"target\"] is not None:\n",
    "    constraints.append(ovoid_surface_group[\"matrix\"] @ updated_times <= ovoid_surface_group[\"target\"])\n",
    "if ovoid_5mm_group[\"matrix\"].size:\n",
    "    doses_cgy = ovoid_5mm_group[\"matrix\"] @ updated_times\n",
    "    doses_gy = doses_cgy / 100.0\n",
    "    eqd2_bt_expr = bt_eqd2_scale * (cp.square(doses_gy) + alpha_beta_gy * doses_gy)\n",
    "    eqd2_limits = np.full(eqd2_bt_expr.shape, eqd2_allowable_bt_gy, dtype=float)\n",
    "    constraints.append(eqd2_bt_expr <= eqd2_limits)\n",
    "\n",
    "objective = cp.Minimize(cp.sum_squares(delta))\n",
    "prob = cp.Problem(objective, constraints)\n",
    "prob.solve(solver=cp.SCS, warm_start=True)\n",
    "print(f\"Solver status: {prob.status}, objective: {prob.value:.4f}\")\n",
    "if prob.status not in (\"optimal\", \"optimal_inaccurate\"):\n",
    "    raise RuntimeError(\"Convex optimisation failed to find a feasible solution.\")\n",
    "optimised_times = np.maximum(np.asarray(updated_times.value, dtype=float).ravel(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30d9de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwell_summary = pd.DataFrame(dwell_records)\n",
    "dwell_summary[\"plan_time_s\"] = baseline_times\n",
    "dwell_summary[\"optimised_time_s\"] = optimised_times\n",
    "dwell_summary[\"delta_s\"] = dwell_summary[\"optimised_time_s\"] - dwell_summary[\"plan_time_s\"]\n",
    "plan_vals = dwell_summary[\"plan_time_s\"].to_numpy()\n",
    "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "    percent = np.where(\n",
    "        np.abs(plan_vals) > 1e-6,\n",
    "        dwell_summary[\"delta_s\"] / dwell_summary[\"plan_time_s\"],\n",
    "        np.nan,\n",
    "    )\n",
    "dwell_summary[\"percent_change\"] = percent\n",
    "\n",
    "reference_rows_expanded: List[Dict[str, Any]] = []\n",
    "for group_name, group_data in constraint_groups.items():\n",
    "    matrix = group_data[\"matrix\"]\n",
    "    if not matrix.size:\n",
    "        continue\n",
    "    plan_doses = matrix @ baseline_times\n",
    "    opt_doses = matrix @ optimised_times\n",
    "    for idx, meta in enumerate(group_data[\"rows\"]):\n",
    "        record = dict(meta)\n",
    "        record[\"plan_dose_cgy\"] = plan_doses[idx]\n",
    "        record[\"optimised_dose_cgy\"] = opt_doses[idx]\n",
    "        if group_name == \"ovoid_5mm\":\n",
    "            plan_dose_gy = plan_doses[idx] / 100.0\n",
    "            opt_dose_gy = opt_doses[idx] / 100.0\n",
    "            plan_eqd2_bt = bt_eqd2_scale * (plan_dose_gy ** 2 + alpha_beta_gy * plan_dose_gy)\n",
    "            opt_eqd2_bt = bt_eqd2_scale * (opt_dose_gy ** 2 + alpha_beta_gy * opt_dose_gy)\n",
    "            record[\"plan_eqd2_total_gy\"] = plan_eqd2_bt + eqd2_ebrt_gy\n",
    "            record[\"optimised_eqd2_total_gy\"] = opt_eqd2_bt + eqd2_ebrt_gy\n",
    "            record[\"limit_eqd2_total_gy\"] = eqd2_limit_total_gy\n",
    "            record[\"slack_eqd2_gy\"] = eqd2_limit_total_gy - record[\"optimised_eqd2_total_gy\"]\n",
    "            record[\"slack_cgy\"] = np.nan\n",
    "        else:\n",
    "            record[\"plan_eqd2_total_gy\"] = np.nan\n",
    "            record[\"optimised_eqd2_total_gy\"] = np.nan\n",
    "            record[\"limit_eqd2_total_gy\"] = np.nan\n",
    "            record[\"slack_eqd2_gy\"] = np.nan\n",
    "            target_val = record.get(\"target_dose_cgy\", np.nan)\n",
    "            if np.isfinite(target_val):\n",
    "                record[\"slack_cgy\"] = record[\"optimised_dose_cgy\"] - target_val\n",
    "            else:\n",
    "                record[\"slack_cgy\"] = np.nan\n",
    "        reference_rows_expanded.append(record)\n",
    "\n",
    "if reference_rows_expanded:\n",
    "    reference_report = pd.DataFrame(reference_rows_expanded)\n",
    "else:\n",
    "    reference_report = pd.DataFrame(columns=[\n",
    "        \"group\", \"subset\", \"point_index\", \"point_cm\", \"constraint_kind\",\n",
    "        \"target_dose_cgy\", \"plan_dose_cgy\", \"optimised_dose_cgy\", \"slack_cgy\",\n",
    "        \"plan_eqd2_total_gy\", \"optimised_eqd2_total_gy\", \"limit_eqd2_total_gy\", \"slack_eqd2_gy\",\n",
    "    ])\n",
    "reference_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73973889",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reference_report.empty:\n",
    "    print('No reference dose data available for plotting.')\n",
    "else:\n",
    "    dose_df = reference_report[reference_report['constraint_kind'] != 'eqd2_upper'].copy()\n",
    "    if dose_df.empty:\n",
    "        print('No linear dose constraints to plot.')\n",
    "    else:\n",
    "        dose_df['label'] = dose_df['subset'] + '_' + dose_df['point_index'].astype(str)\n",
    "        x = np.arange(len(dose_df))\n",
    "        width = 0.35\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "        ax.bar(x - width/2, dose_df['plan_dose_cgy'], width, label='Plan')\n",
    "        ax.bar(x + width/2, dose_df['optimised_dose_cgy'], width, label='Optimised')\n",
    "        ax.axhline(prescription_dose_cgy, color='k', linestyle='--', linewidth=1.0, label='100% Rx')\n",
    "        ax.axhline(prescription_dose_cgy * 1.4, color='r', linestyle=':', linewidth=1.0, label='140% Rx')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(dose_df['label'], rotation=45, ha='right')\n",
    "        ax.set_ylabel('Dose (cGy)')\n",
    "        ax.set_title('Reference Point Dose Comparison')\n",
    "        ax.legend(ncol=2, bbox_to_anchor=(1.0, 1.15))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    eqd_df = reference_report[reference_report['constraint_kind'] == 'eqd2_upper'][[\n",
    "        'subset', 'point_index', 'plan_eqd2_total_gy', 'optimised_eqd2_total_gy', 'limit_eqd2_total_gy'\n",
    "    ]]\n",
    "    if not eqd_df.empty:\n",
    "        display(eqd_df.rename(columns={\n",
    "            'plan_eqd2_total_gy': 'plan_EQD2_total_Gy',\n",
    "            'optimised_eqd2_total_gy': 'optimised_EQD2_total_Gy',\n",
    "            'limit_eqd2_total_gy': 'limit_EQD2_total_Gy',\n",
    "        }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74bb215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_channel_dwell_times(channel, candidate_times, *, atol_cm: float = 1e-3):\n",
    "    \"\"\"Return dwell times aligned with the RTPLAN channel layout.\n",
    "\n",
    "    Optimisation steps can drop duplicate dwell positions, so this function\n",
    "    re-inserts zero-duration placeholders whenever consecutive control points\n",
    "    share the same coordinates (within ``atol_cm``).\n",
    "    \"\"\"\n",
    "    positions = [np.asarray(p, dtype=float) for p in channel.positions_cm if p is not None]\n",
    "    candidate = np.asarray(candidate_times, dtype=float)\n",
    "    if not positions:\n",
    "        empty = np.zeros((0,), dtype=float)\n",
    "        return empty, empty.astype(bool)\n",
    "\n",
    "    duplicate_mask = np.zeros(len(positions), dtype=bool)\n",
    "    if candidate.size == len(positions):\n",
    "        return candidate.copy(), duplicate_mask\n",
    "\n",
    "    expanded = []\n",
    "    idx = 0\n",
    "    prev = None\n",
    "    for pos_idx, pos in enumerate(positions):\n",
    "        if prev is not None:\n",
    "            expanded.append(0.0)\n",
    "            duplicate_mask[pos_idx] = True\n",
    "            continue\n",
    "        if idx >= candidate.size:\n",
    "            raise ValueError(\"Optimised dwell list shorter than channel topology.\")\n",
    "        expanded.append(float(candidate[idx]))\n",
    "        idx += 1\n",
    "        prev = pos\n",
    "    if idx != candidate.size:\n",
    "        raise ValueError(\"Optimised dwell list longer than channel topology.\")\n",
    "    return np.asarray(expanded, dtype=float), duplicate_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c585600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dwell_summary_sorted = dwell_summary.sort_values([\"channel_label\", \"local_index\"]).reset_index(drop=True)\n",
    "updated_dwells = copy.deepcopy(dwells)\n",
    "applied_rows = []\n",
    "duplicate_report: Dict[str, int] = {}\n",
    "\n",
    "for channel_idx, label in enumerate(required_channels):\n",
    "    channel = rt_channels[channel_idx]\n",
    "    indices = channel_map[channel_idx]\n",
    "    candidate = dwell_summary_sorted.loc[\n",
    "        dwell_summary_sorted[\"channel_label\"] == label,\n",
    "        \"optimised_time_s\",\n",
    "    ].to_numpy()\n",
    "    expanded_times, duplicate_mask = expand_channel_dwell_times(channel, candidate, atol_cm=1e-4)\n",
    "    if expanded_times.size != len(indices):\n",
    "        raise ValueError(\n",
    "            f\"Expanded dwell schedule for {label} has {expanded_times.size} entries, \"\n",
    "            f\"but the RTPLAN channel expects {len(indices)}.\"\n",
    "        )\n",
    "    duplicate_report[label] = int(duplicate_mask.sum())\n",
    "    for local_idx, (dwell_idx, new_time, is_dup) in enumerate(zip(indices, expanded_times, duplicate_mask)):\n",
    "        baseline_time = dwells[dwell_idx].dwell_time_s\n",
    "        new_time = float(new_time)\n",
    "        updated_dwells[dwell_idx].dwell_time_s = new_time\n",
    "        applied_rows.append({\n",
    "            \"channel_label\": label,\n",
    "            \"channel_number\": channel.channel_number,\n",
    "            \"local_index\": local_idx,\n",
    "            \"dwell_index\": dwell_idx,\n",
    "            \"is_duplicate\": bool(is_dup),\n",
    "            \"plan_time_s\": baseline_time,\n",
    "            \"optimised_time_s\": new_time,\n",
    "            \"delta_s\": new_time - baseline_time,\n",
    "        })\n",
    "\n",
    "scaled_channels = dosecal.rebuild_channels(rt_channels_ecs, updated_dwells)\n",
    "\n",
    "print(\"Restored duplicate dwell placeholders per channel:\")\n",
    "for label in required_channels:\n",
    "    print(f\"  {label}: {duplicate_report.get(label, 0)}\")\n",
    "\n",
    "applied_dwell_summary = pd.DataFrame(applied_rows)\n",
    "applied_dwell_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dfbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(dhelp)\n",
    "\n",
    "def convert_physical_to_continuous_index(ct_image, physical_mm):\n",
    "\n",
    "    physical_mm = np.array(physical_mm, dtype=float)*10\n",
    "    if len(physical_mm.shape) == 1:\n",
    "        return ct_image.TransformPhysicalPointToContinuousIndex(physical_mm)\n",
    "    else:\n",
    "        results = []\n",
    "        for idx_mm in range(physical_mm.shape[0]):\n",
    "            point_mm = physical_mm[idx_mm, :]\n",
    "            idx_cont = ct_image.TransformPhysicalPointToContinuousIndex(physical_mm[idx_mm, :])\n",
    "            results.append(idx_cont)\n",
    "        return results\n",
    "\n",
    "coords_art = []\n",
    "coords_art.append(convert_physical_to_continuous_index(ct_ecs_image, reference_points_ecs['Alt']))\n",
    "coords_art.append(convert_physical_to_continuous_index(ct_ecs_image, reference_points_ecs['Art']))\n",
    "coords_art = np.array(coords_art)\n",
    "\n",
    "coords_ref = []\n",
    "for name_ref in reference_sets_ecs.keys():\n",
    "    coords_ref.extend(convert_physical_to_continuous_index(ct_ecs_image, reference_sets_ecs[name_ref]))\n",
    "coords_ref = np.array(coords_ref)\n",
    "\n",
    "\n",
    "dose_result = dosecal.calculate_and_resample_to_ct(\n",
    "    ct_image=ct_ecs_image,\n",
    "    channels=scaled_channels,\n",
    "    anisotropy_path=cfg['hyperparams']['anisotropy_table'],\n",
    "    radial_path=cfg['hyperparams']['radial_table'],\n",
    ")\n",
    "\n",
    "dose_array = dose_result.resampled_array\n",
    "\n",
    "x_ticks = range(ct_ecs_metadata[\"size\"][0])\n",
    "y_ticks = range(ct_ecs_metadata[\"size\"][1])\n",
    "z_ticks = range(ct_ecs_metadata[\"size\"][2])\n",
    "\n",
    "x_coords_mm = np.array(np.array(x_ticks) * ct_ecs_metadata[\"spacing\"][0], dtype=int)\n",
    "y_coords_mm = np.array(np.array(y_ticks) * ct_ecs_metadata[\"spacing\"][1], dtype=int)\n",
    "z_coords_mm = np.array(np.array(z_ticks) * ct_ecs_metadata[\"spacing\"][2], dtype=int)\n",
    "\n",
    "view_axial = dose_array[np.argmax(np.sum(dose_array, axis=(1, 2))), :, :]\n",
    "view_coronal = dose_array[:, np.argmax(np.sum(dose_array, axis=(0, 2))), :]\n",
    "view_sagittal = dose_array[:, :, np.argmax(np.sum(dose_array, axis=(0, 1)))]\n",
    "dwell_info = dhelp.extract_dwell_positions_continuous_index(ct_ecs_image, rt_channels_ecs)\n",
    "dwell_positions = np.array(dwell_info['position'])\n",
    "display_offet = 1.5\n",
    "\n",
    "vmin, vmax = 0, prescription_dose_cgy * 2\n",
    "iso_levels = np.array([0.5, 1.0, 2.0]) * prescription_dose_cgy  # cGy\n",
    "iso_colors = [\"yellow\",\"orange\",\"red\"]\n",
    "iso_labels = ['50%', '100%', '200%']\n",
    "print(prescription_dose_cgy, iso_levels)\n",
    "\n",
    "fontsize = 8 \n",
    "tick_step = 10\n",
    "z_tick_step = max(1, tick_step // 2)\n",
    "alpha = 0.3\n",
    "\n",
    "plt.figure(figsize=(12, 4.5), dpi=100)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(view_axial, interpolation='bilinear', aspect=\"auto\", cmap=\"jet\", vmin=vmin, vmax=vmax)\n",
    "cs1= plt.contour(view_axial, levels=iso_levels, colors=iso_colors, linewidths=2.0)\n",
    "proxy = [plt.Rectangle((0,0),1,1, fc=iso_color) for iso_color in iso_colors]\n",
    "plt.legend(proxy, iso_labels)\n",
    "plt.scatter(dwell_positions[:, 0]-display_offet, dwell_positions[:, 1], s=20, marker='o', edgecolors=\"#ffffff\", linewidths=1.5, color=\"#3cff00\")\n",
    "plt.scatter(coords_art[:, 0]-display_offet, coords_art[:, 1], s=20, marker='x', edgecolors=\"#ffffff\", linewidths=1.5, color=\"#000000\")\n",
    "plt.scatter(coords_ref[:, 0]-display_offet, coords_ref[:, 1], s=20, marker='o', edgecolors=\"#ffffff\", linewidths=1.5, color=\"#FF00AA\")\n",
    "plt.xticks(ticks=x_ticks[::tick_step], labels=np.round(x_coords_mm[::tick_step], 1), rotation=90)\n",
    "plt.yticks(ticks=y_ticks[::tick_step], labels=np.round(y_coords_mm[::tick_step], 1))\n",
    "x_center = 250\n",
    "y_center = 250\n",
    "size_zoom = 128\n",
    "plt.xlim(x_center-size_zoom//2, x_center+size_zoom//2)\n",
    "plt.ylim(y_center+size_zoom//2, y_center-size_zoom//2)\n",
    "plt.xlabel(\"Right-Left (mm)\")\n",
    "plt.ylabel(\"Anterior-Posterior (mm)\")\n",
    "plt.grid(linewidth=0.3, color=\"lime\", linestyle=\"--\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(view_coronal, interpolation='bilinear', aspect=\"auto\", cmap=\"jet\", vmin=vmin, vmax=vmax)\n",
    "cs2 = plt.contour(view_coronal, levels=iso_levels, colors=iso_colors, linewidths=2.0)\n",
    "proxy = [plt.Rectangle((0,0),1,1, fc=iso_color) for iso_color in iso_colors]\n",
    "plt.legend(proxy, iso_labels)\n",
    "plt.scatter(dwell_positions[:, 0]-display_offet, dwell_positions[:, 2], s=20, marker='o', edgecolors=\"#ffffff\", linewidths=1.5, color=\"#3cff00\")\n",
    "plt.scatter(coords_art[:, 0]-display_offet, coords_art[:, 2], s=20, marker='x', edgecolors=\"#ffffff\", linewidths=1.5, color=\"#000000\")\n",
    "plt.scatter(coords_ref[:, 0]-display_offet, coords_ref[:, 2], s=20, marker='o', edgecolors=\"#ffffff\", linewidths=1.5, color=\"#FF00AA\")\n",
    "plt.xticks(ticks=x_ticks[::tick_step], labels=np.round(x_coords_mm[::tick_step], 1), rotation=90)\n",
    "plt.yticks(ticks=z_ticks[::z_tick_step], labels=np.round(z_coords_mm[::z_tick_step], 1))\n",
    "x_center = 250\n",
    "y_center = 275\n",
    "size_zoom_x = 128\n",
    "size_zoom_y = 128\n",
    "plt.xlim(x_center-size_zoom_x//2, x_center+size_zoom_x//2)\n",
    "plt.ylim(y_center-size_zoom_y//2, y_center+size_zoom_y//2)\n",
    "plt.xlabel(\"Right-Left (mm)\")\n",
    "plt.ylabel(\"Superior-Inferior (mm)\")\n",
    "plt.grid(linewidth=0.3, color=\"lime\", linestyle=\"--\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(view_sagittal, interpolation='bilinear', aspect=\"auto\", cmap=\"jet\", vmin=vmin, vmax=vmax)\n",
    "cs3= plt.contour(view_sagittal, levels=iso_levels, colors=iso_colors, linewidths=2.0)\n",
    "proxy = [plt.Rectangle((0,0),1,1, fc=iso_color) for iso_color in iso_colors]\n",
    "plt.legend(proxy, iso_labels)\n",
    "plt.scatter(dwell_positions[:, 1]-display_offet, dwell_positions[:, 2], s=20, marker='o', edgecolors=\"#ffffff\", linewidths=1.5, color=\"#3cff00\")\n",
    "plt.scatter(coords_art[:, 1]-display_offet, coords_art[:, 2], s=20, marker='x', edgecolors=\"#ffffff\", linewidths=1.5, color=\"#000000\")\n",
    "plt.scatter(coords_ref[:, 1]-display_offet, coords_ref[:, 2], s=20, marker='o', edgecolors=\"#ffffff\", linewidths=1.5, color=\"#FF00AA\")\n",
    "plt.xticks(ticks=y_ticks[::tick_step], labels=np.round(y_coords_mm[::tick_step], 1), rotation=90)\n",
    "plt.yticks(ticks=z_ticks[::z_tick_step], labels=np.round(z_coords_mm[::z_tick_step], 1))\n",
    "x_center = 260\n",
    "y_center = 275\n",
    "size_zoom_x = 128\n",
    "size_zoom_y = 128\n",
    "plt.xlim(x_center-size_zoom_x//2, x_center+size_zoom_x//2)\n",
    "plt.ylim(y_center-size_zoom_y//2, y_center+size_zoom_y//2)\n",
    "plt.xlabel(\"Anterior-Posterior (mm)\")\n",
    "plt.ylabel(\"Superior-Inferior (mm)\")\n",
    "plt.grid(linewidth=0.3, color=\"lime\", linestyle=\"--\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04e0a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".uvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
